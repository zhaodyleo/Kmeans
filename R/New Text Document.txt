.kmeans_cluster_multi <- function(X, center, max.iter, tol) {
  # determine whether the loss coverage
  check.tol <- function(fmax,fmin,ftol){
    delta <- abs(fmax - fmin)
    accuracy <- (abs(fmax) + abs(fmin))*ftol
    return(delta < (accuracy + tol))
  }
  X <- data.matrix(X)
  N <- nrow(X)
  p <- ncol(X)
  nclust <- NULL
  # check whether randomly assigned initial centres or use the input one
  if(is.null(dim(center))){
    nclust <- length(center)
  }else{
    nclust <- ncol(center)
  }
  # initialized the centres and label
  if(length(unique(center)) != 1){
    Cluster_index <- NULL
    mu <- center
  }else{
    Cluster_index <- sample(1:nclust,N,replace = TRUE)
    mu <- sapply(1:nclust,
                 FUN = function(i) colMeans(X[Cluster_index == i,]))
  }
  # initialized the loss
  SumofSquare_Loss <- 10^10
  for(i in 1:max.iter){
    SumofSquare_Loss0 <- SumofSquare_Loss
    # apply the E step of algorithm which update
    # sum of square loss, labels
    SumOfSquare_diff <- apply(mu,
                              MARGIN = 2,
                              FUN = function(i) rowSums((sweep(X,MARGIN = 2,FUN = "-",i))^2))
    Cluster_index <- apply(SumOfSquare_diff,
                           MARGIN = 1,
                           FUN = function(i) which.min(i))
    SumofSquare_Loss <- sum(t(SumOfSquare_diff)[Cluster_index + seq(0,N * nclust - nclust,nclust)])/N
    # apply the M step of algorithm which update the centres
    mu <- sapply(1:nclust,
                 FUN = function(i) colMeans(X[Cluster_index == i,]))
    # check whether loss converge
    if(check.tol(SumofSquare_Loss0,SumofSquare_Loss,tol)){
      break
    }
  }
  return(list(mus <- mu,est <- Cluster_index))
}


